{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b5424e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49b5424e",
    "outputId": "7ccfabbc-196d-4963-d0af-901eff1e872b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16ae58dce50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyepo\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9394215",
   "metadata": {},
   "source": [
    "### Number of Cores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c6795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of nodes\n",
    "nodes = [20, 50, 100, 200, 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b719f2f1",
   "metadata": {},
   "source": [
    "###  Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874d51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, num_feat, num_node):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, num_node*(num_node-1)//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3fd00",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "476e56ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Dec 06 06:05:32 PM: Encountered unexpected exception importing solver OSQP:\n",
      "ImportError('DLL load failed while importing qdldl: The specified module could not be found.')\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import pyepo\n",
    "from pyepo.func import perturbedFenchelYoung\n",
    "\n",
    "from model import tspDFJModel\n",
    "from dataset import optDatasetConstrs\n",
    "from func import innerConeAlignedCosine\n",
    "from dataset import collate_fn\n",
    "\n",
    "def pipeline():\n",
    "    num_data = 10 # number of training data\n",
    "    num_feat = 10 # size of feature\n",
    "    deg = 4 # polynomial degree\n",
    "    e = 0.5 # noise width\n",
    "    batch_size = 32 # batch size\n",
    "    elapseds_cave, elapseds_pfyl = [], []\n",
    "    for num_node in nodes:\n",
    "        print(\"Num of Node:\", num_node)\n",
    "        # set random seed\n",
    "        np.random.seed(42)\n",
    "        torch.manual_seed(42)\n",
    "        # generate data\n",
    "        feats, costs = pyepo.data.tsp.genData(num_data, num_feat, num_node, deg, e, seed=42)\n",
    "        # set solver\n",
    "        optmodel = tspDFJModel(num_node)\n",
    "        # dataset and data loader\n",
    "        dataset = optDatasetConstrs(optmodel, feats, costs=costs)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "        # init model\n",
    "        reg = LinearRegression(num_feat, num_node)\n",
    "        # train\n",
    "        print(\"CaVE+:\")\n",
    "        time.sleep(1)\n",
    "        elapsed = trainingProcessCaVE(reg, optmodel, dataloader)\n",
    "        elapseds_cave.append(elapsed / num_data)\n",
    "        print()\n",
    "        print(\"PFYL:\")\n",
    "        time.sleep(1)\n",
    "        elapsed = trainingProcessPFYL(reg, optmodel, dataloader)\n",
    "        elapseds_pfyl.append(elapsed / num_data)\n",
    "        print()\n",
    "        print()\n",
    "    return elapseds_cave, elapseds_pfyl\n",
    "\n",
    "\n",
    "def trainingProcessCaVE(reg, optmodel, dataloader):\n",
    "    # copy predictor\n",
    "    reg = copy.deepcopy(reg)\n",
    "    # init loss\n",
    "    ca_cos = innerConeAlignedCosine(optmodel, solver=\"clarabel\")\n",
    "    # train\n",
    "    elapsed = trainCaVE(reg, ca_cos, dataloader)\n",
    "    # print\n",
    "    time.sleep(1)\n",
    "    print(\"Test Elapsed Time: {:.2f} Sec\".format(elapsed))\n",
    "    return elapsed\n",
    "\n",
    "        \n",
    "def trainCaVE(reg, loss_func, dataloader):\n",
    "    # set optimizer\n",
    "    optimizer = torch.optim.Adam(reg.parameters(), lr=5e-2)\n",
    "    # training\n",
    "    tbar = tqdm(dataloader)\n",
    "    tick = time.time()\n",
    "    for data in tbar:\n",
    "        # forward pass\n",
    "        x, _, _, t_ctr = data\n",
    "        # predict\n",
    "        cp = reg(x)\n",
    "        # loss\n",
    "        loss = loss_func(cp, t_ctr)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tbar.set_description(\"Loss: {:8.4f}\".format(loss.item()))\n",
    "    # record time\n",
    "    tock = time.time()\n",
    "    elapsed = tock - tick\n",
    "    return elapsed\n",
    "\n",
    "def trainingProcessPFYL(reg, optmodel, dataloader):\n",
    "    # copy predictor\n",
    "    reg = copy.deepcopy(reg)\n",
    "    # init loss\n",
    "    pfy = perturbedFenchelYoung(optmodel, n_samples=1, sigma=1.0)\n",
    "    # train\n",
    "    elapsed = trainPFYL(reg, pfy, dataloader)\n",
    "    # print\n",
    "    time.sleep(1)\n",
    "    print(\"Test Elapsed Time: {:.2f} Sec\".format(elapsed))\n",
    "    return elapsed\n",
    "\n",
    "        \n",
    "def trainPFYL(reg, loss_func, dataloader):\n",
    "    # set optimizer\n",
    "    optimizer = torch.optim.Adam(reg.parameters(), lr=5e-2)\n",
    "    # training\n",
    "    tbar = tqdm(dataloader)\n",
    "    tick = time.time()\n",
    "    for data in tbar:\n",
    "        # forward pass\n",
    "        x, _, w, _ = data\n",
    "        # predict\n",
    "        cp = reg(x)\n",
    "        # loss\n",
    "        loss = loss_func(cp, w)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tbar.set_description(\"Loss: {:8.4f}\".format(loss.item()))\n",
    "    # record time\n",
    "    tock = time.time()\n",
    "    elapsed = tock - tick\n",
    "    return elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd49c9",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c82b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import tol_colors as tc\n",
    "\n",
    "def plot(nodes, elapseds_cave, elapsed_pfyl):\n",
    "    # color map\n",
    "    cset = tc.tol_cset('light')\n",
    "    # time\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    plt.plot(nodes, elapseds_cave, marker=\"o\", linestyle=\"--\", markersize=10, lw=5, color=cset.orange, label=\"CaVE+\")\n",
    "    plt.plot(nodes, elapsed_pfyl, marker=\"o\", linestyle=\"--\", markersize=10, lw=5, color=cset.light_blue, label=\"PFYL\")\n",
    "    plt.xlabel(\"Num of Nodes\", fontsize=36)\n",
    "    plt.ylabel(\"Runtime (Sec)\", fontsize=36)\n",
    "    plt.xticks(ticks=nodes, fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.legend(fontsize=32)\n",
    "    plt.title(\"Average Training Time per Instance\", fontsize=36)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe5e23",
   "metadata": {},
   "source": [
    "### Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c7a65c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Node: 20\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-01\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 63.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaVE+:\n",
      "Num of cores: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py:1403: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Loss:  -0.7984: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Elapsed Time: 1.10 Sec\n",
      "\n",
      "PFYL:\n",
      "Num of cores: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  35.6000: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Elapsed Time: 0.10 Sec\n",
      "\n",
      "\n",
      "Num of Node: 50\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaVE+:\n",
      "Num of cores: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  -0.9099: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Elapsed Time: 0.55 Sec\n",
      "\n",
      "PFYL:\n",
      "Num of cores: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  96.4000: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Elapsed Time: 0.57 Sec\n",
      "\n",
      "\n",
      "Num of Node: 100\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:23<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaVE+:\n",
      "Num of cores: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  -0.9364: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Elapsed Time: 5.93 Sec\n",
      "\n",
      "PFYL:\n",
      "Num of cores: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 195.2000: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Elapsed Time: 3.61 Sec\n",
      "\n",
      "\n",
      "Num of Node: 200\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [06:16<00:00, 37.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaVE+:\n",
      "Num of cores: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1616516800 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m elapseds_cave, elapsed_pfyl \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaVE+:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m \u001b[43mtrainingProcessCaVE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m elapseds_cave\u001b[38;5;241m.\u001b[39mappend(elapsed \u001b[38;5;241m/\u001b[39m num_data)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 57\u001b[0m, in \u001b[0;36mtrainingProcessCaVE\u001b[1;34m(reg, optmodel, dataloader)\u001b[0m\n\u001b[0;32m     55\u001b[0m ca_cos \u001b[38;5;241m=\u001b[39m innerConeAlignedCosine(optmodel, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclarabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m \u001b[43mtrainCaVE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# print\u001b[39;00m\n\u001b[0;32m     59\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 70\u001b[0m, in \u001b[0;36mtrainCaVE\u001b[1;34m(reg, loss_func, dataloader)\u001b[0m\n\u001b[0;32m     68\u001b[0m tbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader)\n\u001b[0;32m     69\u001b[0m tick \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tbar:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     x, _, _, t_ctr \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# predict\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\OneDrive\\Study\\UofT\\Research\\CAVE\\dataset.py:222\u001b[0m, in \u001b[0;36moptDatasetConstrs.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    213\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeats[index]),\n\u001b[0;32m    214\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msols[index]),\n\u001b[0;32m    215\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctrs[index])\n\u001b[0;32m    216\u001b[0m     )\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    219\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeats[index]),\n\u001b[0;32m    220\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosts[index]),\n\u001b[0;32m    221\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msols[index]),\n\u001b[1;32m--> 222\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1616516800 bytes."
     ]
    }
   ],
   "source": [
    "elapseds_cave, elapsed_pfyl = pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f8e31e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elapseds_cave' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot(nodes, \u001b[43melapseds_cave\u001b[49m, elapsed_pfyl)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'elapseds_cave' is not defined"
     ]
    }
   ],
   "source": [
    "plot(nodes, elapseds_cave, elapsed_pfyl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065502e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
