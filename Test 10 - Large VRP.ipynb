{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b5424e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49b5424e",
    "outputId": "7ccfabbc-196d-4963-d0af-901eff1e872b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x172c8267f30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyepo\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5be4e",
   "metadata": {
    "id": "53e5be4e"
   },
   "source": [
    "## Data Set and Optimization Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e3bd4d",
   "metadata": {
    "id": "00e3bd4d"
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "num_node = 30 # node size\n",
    "num_data = 1000 # number of training data\n",
    "num_feat = 10 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "e = 0.5 # noise width\n",
    "feats, costs = pyepo.data.tsp.genData(num_data+100+1000, num_feat, num_node+1, deg, e, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6073c3f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6073c3f4",
    "outputId": "e5734002-11c7-44d6-a6ba-006b39d0d4e5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-10-22\n",
      "Obj: 64.5109\n",
      "0 -> 2 -> 14 -> 26 -> 20 -> 1 -> 16 -> 30 -> 0\n",
      "0 -> 3 -> 28 -> 21 -> 24 -> 11 -> 15 -> 5 -> 17 -> 0\n",
      "0 -> 7 -> 18 -> 9 -> 6 -> 10 -> 19 -> 23 -> 0\n",
      "0 -> 8 -> 12 -> 22 -> 29 -> 0\n",
      "0 -> 13 -> 25 -> 4 -> 27 -> 0\n"
     ]
    }
   ],
   "source": [
    "from model import vrpModel\n",
    "# demands\n",
    "demands = np.random.rand(num_node) * 10\n",
    "# set solver\n",
    "optmodel = vrpModel(num_node+1, demands=demands, capacity=30, num_vehicle=8)\n",
    "# set time limit\n",
    "optmodel._model.Params.timelimit = 60\n",
    "# solve\n",
    "optmodel.setObj(costs[0])\n",
    "sol, obj = optmodel.solve()\n",
    "print(\"Obj: {:.4f}\".format(obj))\n",
    "route = optmodel.getTour(sol)\n",
    "for tour in route:\n",
    "    print(\" -> \".join(map(str, tour)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd160ac7",
   "metadata": {},
   "source": [
    "### Load  Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005acf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tensors\n",
    "x_train = torch.load(\"./data/feats_train_vrp30.pt\")\n",
    "c_train = torch.load(\"./data/costs_train_vrp30.pt\")\n",
    "w_train = torch.load(\"./data/sols_train_vrp30.pt\")\n",
    "ctr_train = torch.load(\"./data/ctrs_train_vrp30.pt\")\n",
    "\n",
    "# save tensors\n",
    "x_test = torch.load(\"./data/feats_test_vrp30.pt\")[:10]\n",
    "c_test = torch.load(\"./data/costs_test_vrp30.pt\")[:10]\n",
    "w_test = torch.load(\"./data//sols_test_vrp30.pt\")[:10]\n",
    "ctr_test = torch.load(\"./data//ctrs_test_vrp30.pt\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1e64dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac1e64dd",
    "outputId": "cfa534b0-e50f-4e05-ac72-374fe07eccf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 933/933 [00:20<00:00, 45.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 52.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 933/933 [00:32<00:00, 28.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# ceate dataset with a dummy solver\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from pyepo.model.grb.grbmodel import optGrbModel\n",
    "class dummyModel(optGrbModel):\n",
    "    def _getModel(self):\n",
    "        # ceate a model\n",
    "        m = gp.Model()\n",
    "        # varibles\n",
    "        x = m.addVars(c_train.shape[1], name=\"x\", vtype=GRB.BINARY)\n",
    "        # model sense\n",
    "        m.modelSense = GRB.MAXIMIZE\n",
    "        return m, x\n",
    "    \n",
    "# set solver\n",
    "dummy_model = dummyModel()\n",
    "# get training, validation and test dataset\n",
    "dataset_train_cost = pyepo.data.dataset.optDataset(dummy_model, x_train, costs=c_train)\n",
    "dataset_test = pyepo.data.dataset.optDataset(dummy_model, x_test, costs=c_test)\n",
    "from dataset import optDatasetConstrs\n",
    "dataset_train = optDatasetConstrs(dummy_model, x_train, costs=c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72961e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add VRP data\n",
    "dataset_train_cost.feats = x_train\n",
    "dataset_train_cost.costs = c_train\n",
    "dataset_train_cost.sols = w_train\n",
    "dataset_train_cost.objs = torch.sum(c_train*w_train, dim=1)\n",
    "dataset_train.feats = x_train\n",
    "dataset_train.costs = c_train\n",
    "dataset_train.sols = w_train\n",
    "dataset_train.ctrs = ctr_train\n",
    "dataset_test.feats = x_test\n",
    "dataset_test.costs = c_test\n",
    "dataset_test.sols = w_test\n",
    "dataset_test.objs = torch.sum(c_test*w_test, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77111dd8",
   "metadata": {
    "id": "77111dd8"
   },
   "outputs": [],
   "source": [
    "# get data loader\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import collate_fn\n",
    "batch_size = 32\n",
    "loader_train_cost = DataLoader(dataset_train_cost, batch_size=batch_size, shuffle=True)\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2da3",
   "metadata": {
    "id": "c21a2da3"
   },
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49603cb7",
   "metadata": {
    "id": "49603cb7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, num_node*(num_node+1)//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadd8c3",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6359eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot(loss_log, grad_log):\n",
    "    # draw loss plot for training\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(loss_log, color=\"c\", lw=2)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xlabel(\"Iters\", fontsize=36)\n",
    "    plt.ylabel(\"Loss\", fontsize=36)\n",
    "    plt.title(\"Loss Curve on Training Set\", fontsize=36)\n",
    "    plt.show()\n",
    "    # draw grad plot for training\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(grad_log, color=\"g\", alpha=0.5, lw=2)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.gca().yaxis.get_offset_text().set_size(24)\n",
    "    plt.xlabel(\"Iters\", fontsize=36)\n",
    "    plt.ylabel(\"Abs Grad\", fontsize=36)\n",
    "    plt.title(\"Absolute Gradient Curve on Training Set\", fontsize=36)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fb9a6",
   "metadata": {
    "id": "f71fb9a6"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d023ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "log_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86e509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import metric\n",
    "\n",
    "def pipeline(reg, forward_func, loss_func, lr, num_epochs, loader_train, loader_test, seed=42):\n",
    "    # set random seed\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # set optimizer\n",
    "    optimizer = torch.optim.Adam(reg.parameters(), lr=lr)\n",
    "    # init log\n",
    "    loss_log = []\n",
    "    grad_log = []\n",
    "    # running time\n",
    "    elapsed = 0\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for epoch in tbar:\n",
    "        # training\n",
    "        time.sleep(1)\n",
    "        tick = time.time()\n",
    "        for data in loader_train:\n",
    "            # forward pass\n",
    "            loss = forward_func(data, reg, loss_func, grad_log)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_log.append(loss.item())\n",
    "            tbar.set_description(\"Epoch {:4.0f}, Loss: {:8.4f}\".format(epoch, loss.item()))\n",
    "        # record time\n",
    "        tock = time.time()\n",
    "        elapsed += tock - tick\n",
    "    print(\"Training Elapsed Time: {:.2f} Sec\".format(elapsed))\n",
    "    print()\n",
    "    print(\"Plot:\")\n",
    "    plot(loss_log, grad_log)\n",
    "    print()\n",
    "    print(\"Evaluation:\")\n",
    "    tick = time.time()\n",
    "    test_regret, _ = metric.regret(reg, optmodel, loader_test)\n",
    "    tock = time.time()\n",
    "    elapsed = tock - tick\n",
    "    print(\"Test Regret: {:.4f}%\".format(test_regret*100))\n",
    "    print(\"Test Elapsed Time: {:.2f} Sec\".format(elapsed))\n",
    "\n",
    "\n",
    "def forwardCAVE(data, reg, loss_func, grad_log):\n",
    "    # unzip data\n",
    "    x, _, _, t_ctr = data\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # get gradient\n",
    "    cp.register_hook(lambda grad: grad_log.append(abs(grad.cpu().detach().numpy()).sum()))\n",
    "    # loss\n",
    "    loss = loss_func(cp, t_ctr)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32879daf",
   "metadata": {},
   "source": [
    "### 2-Stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8f8e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0931cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# init loss\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "def forward2S(data, reg, loss_func, grad_log):\n",
    "    # unzip data\n",
    "    x, c, w, z = data\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # get gradient\n",
    "    cp.register_hook(lambda grad: grad_log.append(abs(grad.cpu().detach().numpy()).sum()))\n",
    "    # loss\n",
    "    loss = loss_func(cp, c)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36831a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch    9, Loss:   4.6323:  50%|███████████████████████████                           | 10/20 [00:15<00:11,  1.14s/it]"
     ]
    }
   ],
   "source": [
    "lr = 5e-2\n",
    "pipeline(reg, forward2S, mse, lr, num_epochs, loader_train_cost, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251835b",
   "metadata": {},
   "source": [
    "### Inner Method with Clarabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import innerConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = innerConeAlignedCosine(optmodel, solver=\"clarabel\", processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, loader_train, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c70aab9",
   "metadata": {},
   "source": [
    "### Inner & Average Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29728583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634877bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import innerConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = innerConeAlignedCosine(optmodel, solver=\"clarabel\", solve_ratio=0.3, processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, loader_train, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61af1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
