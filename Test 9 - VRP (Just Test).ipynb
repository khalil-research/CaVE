{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b5424e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49b5424e",
    "outputId": "7ccfabbc-196d-4963-d0af-901eff1e872b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2879e733e50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyepo\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5be4e",
   "metadata": {
    "id": "53e5be4e"
   },
   "source": [
    "## Data Set and Optimization Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e3bd4d",
   "metadata": {
    "id": "00e3bd4d"
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "num_node = 20 # node size\n",
    "num_data = 10 # number of training data\n",
    "num_feat = 10 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "e = 0.5 # noise width\n",
    "feats, costs = pyepo.data.tsp.genData(num_data+1+1, num_feat, num_node+1, deg, e, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6073c3f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6073c3f4",
    "outputId": "e5734002-11c7-44d6-a6ba-006b39d0d4e5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-10-22\n",
      "Obj: 61.3303\n",
      "0 -> 1 -> 9 -> 12 -> 0\n",
      "0 -> 3 -> 5 -> 16 -> 4 -> 0\n",
      "0 -> 7 -> 14 -> 15 -> 18 -> 13 -> 20 -> 6 -> 19 -> 17 -> 0\n",
      "0 -> 8 -> 11 -> 2 -> 10 -> 0\n"
     ]
    }
   ],
   "source": [
    "from model import vrpModel\n",
    "# demands\n",
    "demands = np.random.rand(num_node) * 10\n",
    "# set solver\n",
    "optmodel = vrpModel(num_node+1, demands=demands, capacity=30, num_vehicle=5)\n",
    "# solve\n",
    "optmodel.setObj(costs[0])\n",
    "sol, obj = optmodel.solve()\n",
    "print(\"Obj: {:.4f}\".format(obj))\n",
    "route = optmodel.getTour(sol)\n",
    "for tour in route:\n",
    "    print(\" -> \".join(map(str, tour)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976de0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "feats, x_test, costs, c_test = train_test_split(feats, costs, test_size=1, random_state=42)\n",
    "x_train, x_val, c_train, c_val = train_test_split(feats, costs, test_size=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1e64dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac1e64dd",
    "outputId": "cfa534b0-e50f-4e05-ac72-374fe07eccf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 22.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# get training, validation and test dataset\n",
    "dataset_train_cost = pyepo.data.dataset.optDataset(optmodel, x_train, costs=c_train)\n",
    "dataset_val = pyepo.data.dataset.optDataset(optmodel, x_val, costs=c_val)\n",
    "dataset_test = pyepo.data.dataset.optDataset(optmodel, x_test, costs=c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7df499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For optModel, the method 'solve' should return solution vector and objective value.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mD:\\OneDrive\\Study\\UofT\\Research\\CAVE\\dataset.py:68\u001b[0m, in \u001b[0;36moptDatasetConstrs._getSols\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# solve\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     sol, model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# get constrs\u001b[39;00m\n",
      "File \u001b[1;32mD:\\OneDrive\\Study\\UofT\\Research\\CAVE\\dataset.py:105\u001b[0m, in \u001b[0;36moptDatasetConstrs._solve\u001b[1;34m(self, cost)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# copy model\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# set obj\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pyepo\\model\\grb\\grbmodel.py:74\u001b[0m, in \u001b[0;36moptGrbModel.copy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m x \u001b[38;5;241m=\u001b[39m new_model\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgetVars()\n\u001b[1;32m---> 74\u001b[0m new_model\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m {key: x[i] \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)}\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_model\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pyepo\\model\\grb\\grbmodel.py:74\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m x \u001b[38;5;241m=\u001b[39m new_model\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgetVars()\n\u001b[1;32m---> 74\u001b[0m new_model\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m {key: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)}\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_model\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optDatasetConstrs\n\u001b[1;32m----> 2\u001b[0m dataset_train \u001b[38;5;241m=\u001b[39m \u001b[43moptDatasetConstrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\OneDrive\\Study\\UofT\\Research\\CAVE\\dataset.py:51\u001b[0m, in \u001b[0;36moptDatasetConstrs.__init__\u001b[1;34m(self, model, feats, costs, sols)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sols \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosts \u001b[38;5;241m=\u001b[39m costs\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getSols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# get tight constraints\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\OneDrive\\Study\\UofT\\Research\\CAVE\\dataset.py:72\u001b[0m, in \u001b[0;36moptDatasetConstrs._getSols\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m     constrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getBindingConstrs(model)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor optModel, the method \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolve\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should return solution vector and objective value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m     )\n\u001b[0;32m     75\u001b[0m sols\u001b[38;5;241m.\u001b[39mappend(sol)\n\u001b[0;32m     76\u001b[0m ctrs\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(constrs))\n",
      "\u001b[1;31mValueError\u001b[0m: For optModel, the method 'solve' should return solution vector and objective value."
     ]
    }
   ],
   "source": [
    "from dataset import optDatasetConstrs\n",
    "dataset_train = optDatasetConstrs(optmodel, x_train, costs=c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77111dd8",
   "metadata": {
    "id": "77111dd8"
   },
   "outputs": [],
   "source": [
    "# get data loader\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import collate_fn\n",
    "batch_size = 32\n",
    "loader_train_cost = DataLoader(dataset_train_cost, batch_size=batch_size, shuffle=True)\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2da3",
   "metadata": {
    "id": "c21a2da3"
   },
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49603cb7",
   "metadata": {
    "id": "49603cb7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, num_node*(num_node-1)//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadd8c3",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step):\n",
    "    # draw loss plot for training\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(loss_log, color=\"c\", lw=2)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xlabel(\"Iters\", fontsize=36)\n",
    "    plt.ylabel(\"Loss\", fontsize=36)\n",
    "    plt.title(\"Loss Curve on Training Set\", fontsize=36)\n",
    "    plt.show()\n",
    "    # draw grad plot for training\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(grad_log, color=\"g\", alpha=0.5, lw=2)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.gca().yaxis.get_offset_text().set_size(24)\n",
    "    plt.xlabel(\"Iters\", fontsize=36)\n",
    "    plt.ylabel(\"Abs Grad\", fontsize=36)\n",
    "    plt.title(\"Absolute Gradient Curve on Training Set\", fontsize=36)\n",
    "    plt.show()\n",
    "    # draw regret plot for test\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    plt.plot([i * log_step for i in range(len(regret_log_trn))], regret_log_trn,\n",
    "             color=\"royalblue\", ls=\"--\", alpha=0.7, lw=5, label=\"Train\")\n",
    "    plt.plot([i * log_step for i in range(len(regret_log_val))], regret_log_val,\n",
    "             color=\"lightcoral\", ls=\":\", alpha=0.7, lw=5, label=\"Val\")\n",
    "    plt.xlim(-0.5, num_epochs+0.5)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.xticks(range(0, num_epochs+1, 5), fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xlabel(\"Epoch\", fontsize=36)\n",
    "    plt.ylabel(\"Regret\", fontsize=36)\n",
    "    plt.legend(fontsize=32)\n",
    "    plt.title(\"Regret Curve on Training and Validation Set\", fontsize=36)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fb9a6",
   "metadata": {
    "id": "f71fb9a6"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "log_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from earlystop import earlyStopper\n",
    "from clipgrad import clipGrad\n",
    "\n",
    "def pipeline(reg, forward_func, loss_func, lr, num_epochs, \n",
    "             log_step, loader_train, loader_val, loader_test, grad_clip=False, seed=42):\n",
    "    # set random seed\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # set optimizer\n",
    "    optimizer = torch.optim.Adam(reg.parameters(), lr=lr)\n",
    "    # set stopper\n",
    "    stopper = earlyStopper(patience=3)\n",
    "    stop = False\n",
    "    # init best model\n",
    "    best_model_state = copy.deepcopy(reg.state_dict())\n",
    "    best_val_regret = float(\"inf\")\n",
    "    # init log\n",
    "    loss_log = []\n",
    "    grad_log = []\n",
    "    regret_log_trn = []\n",
    "    regret_log_val = []\n",
    "    # running time\n",
    "    elapsed = 0\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for epoch in tbar:\n",
    "        # eval & log\n",
    "        if epoch % log_step == 0:\n",
    "            # regret\n",
    "            regret_trn = pyepo.metric.regret(reg, optmodel, loader_train_cost)\n",
    "            regret_log_trn.append(regret_trn)\n",
    "            regret_val = pyepo.metric.regret(reg, optmodel, loader_val)\n",
    "            regret_log_val.append(regret_val)\n",
    "            tbar.write(\"Epoch {:3}, Train Regret: {:8.4f}%, Val Regret: {:8.4f}%\".format(epoch, regret_trn*100, regret_val*100))\n",
    "            # update best model\n",
    "            if regret_val < best_val_regret:\n",
    "                best_val_regret = regret_val\n",
    "                best_model_state = copy.deepcopy(reg.state_dict())\n",
    "            # early stop\n",
    "            if stopper.stop(regret_val):\n",
    "                print()\n",
    "                stop = True\n",
    "                print(\"Early Stop!\")\n",
    "                break\n",
    "        # training\n",
    "        time.sleep(1)\n",
    "        tick = time.time()\n",
    "        for data in loader_train:\n",
    "            # forward pass\n",
    "            loss = forward_func(data, reg, loss_func, grad_log)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # clip\n",
    "            if grad_clip:\n",
    "                clipGrad(reg, threshold=1e-6)\n",
    "            optimizer.step()\n",
    "            loss_log.append(loss.item())\n",
    "            tbar.set_description(\"Epoch {:4.0f}, Loss: {:8.4f}\".format(epoch, loss.item()))\n",
    "        # record time\n",
    "        tock = time.time()\n",
    "        elapsed += tock - tick\n",
    "    # no early stop\n",
    "    if not stop:\n",
    "        regret_trn = pyepo.metric.regret(reg, optmodel, loader_train_cost)\n",
    "        regret_log_trn.append(regret_trn)\n",
    "        regret_val = pyepo.metric.regret(reg, optmodel, loader_val)\n",
    "        regret_log_val.append(regret_val)\n",
    "        tbar.write(\"Epoch {:3}, Train Regret: {:8.4f}%, Val Regret: {:8.4f}%\".format(epoch, regret_trn*100, regret_val*100))\n",
    "        # update best model\n",
    "        if regret_val < best_val_regret:\n",
    "            best_val_regret = regret_val\n",
    "            best_model_state = copy.deepcopy(reg.state_dict())\n",
    "    print(\"Training Elapsed Time: {:.2f} Sec\".format(elapsed))\n",
    "    # restore best model\n",
    "    reg.load_state_dict(best_model_state)\n",
    "    print()\n",
    "    print(\"Evaluation:\")\n",
    "    tick = time.time()\n",
    "    test_regret = pyepo.metric.regret(reg, optmodel, loader_test)\n",
    "    tock = time.time()\n",
    "    elapsed = tock - tick\n",
    "    print(\"Test Regret: {:.4f}%\".format(test_regret*100))\n",
    "    print(\"Test Elapsed Time: {:.2f} Sec\".format(elapsed))\n",
    "    return loss_log, grad_log, regret_log_trn, regret_log_val\n",
    "\n",
    "\n",
    "def forwardCAVE(data, reg, loss_func, grad_log):\n",
    "    # unzip data\n",
    "    x, _, _, t_ctr = data\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # get gradient\n",
    "    cp.register_hook(lambda grad: grad_log.append(abs(grad.cpu().detach().numpy()).sum()))\n",
    "    # loss\n",
    "    loss = loss_func(cp, t_ctr)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32879daf",
   "metadata": {},
   "source": [
    "### 2-Stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# init loss\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "def forward2S(data, reg, loss_func, grad_log):\n",
    "    # unzip data\n",
    "    x, c, w, z = data\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # get gradient\n",
    "    cp.register_hook(lambda grad: grad_log.append(abs(grad.cpu().detach().numpy()).sum()))\n",
    "    # loss\n",
    "    loss = loss_func(cp, c)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36831a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forward2S, mse, lr, num_epochs, log_step,\n",
    "                                                              loader_train_cost, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0b547",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363243b",
   "metadata": {},
   "source": [
    "### Exact Method with Clarabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6a2e2",
   "metadata": {
    "id": "8dd6a2e2"
   },
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67660513",
   "metadata": {
    "id": "67660513"
   },
   "outputs": [],
   "source": [
    "from func import exactConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = exactConeAlignedCosine(optmodel, solver=\"clarabel\", processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c332205",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c332205",
    "outputId": "b01697bd-80f7-4f58-eb97-35b5276c0ff1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ca51c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "dc6ca51c",
    "outputId": "cb858940-6b51-485d-a90f-a04a9d7a94e5"
   },
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251835b",
   "metadata": {},
   "source": [
    "### Inner Method with Clarabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import innerConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = innerConeAlignedCosine(optmodel, solver=\"clarabel\", processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c70aab9",
   "metadata": {},
   "source": [
    "### Inner & Average Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29728583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634877bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import innerConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = innerConeAlignedCosine(optmodel, solver=\"clarabel\", solve_ratio=0.3, processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2413594",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c0f29",
   "metadata": {
    "id": "adb666a9"
   },
   "source": [
    "### Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import samplingConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = samplingConeAlignedCosine(optmodel, n_samples=100, inner_ratio=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d12efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620fc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07024ad0",
   "metadata": {},
   "source": [
    "### Sampling Method with Cone Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b8235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import samplingConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = samplingConeAlignedCosine(optmodel, n_samples=100, inner_ratio=0.4, check_cone=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a296c",
   "metadata": {},
   "source": [
    "### Average Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a709121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d248ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import avgConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = avgConeAlignedCosine(optmodel, inner_ratio=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1dd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c5edc",
   "metadata": {},
   "source": [
    "###  Average Method with Cone Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfe76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import avgConeAlignedCosine\n",
    "# init loss\n",
    "ca_cos = avgConeAlignedCosine(optmodel, inner_ratio=0.4, check_cone=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardCAVE, ca_cos, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6329ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5d9ae",
   "metadata": {},
   "source": [
    "### PFYL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b835f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9056a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyepo.func import perturbedFenchelYoung\n",
    "# init pfyl loss\n",
    "pfy = perturbedFenchelYoung(optmodel, n_samples=1, sigma=1.0, processes=8)\n",
    "\n",
    "def forwardPFY(data, reg, loss_func, grad_log):\n",
    "    # unzip data\n",
    "    x, _, w, _ = data\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # get gradient\n",
    "    cp.register_hook(lambda grad: grad_log.append(abs(grad.cpu().detach().numpy()).sum()))\n",
    "    # loss\n",
    "    loss = loss_func(cp, w)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardPFY, pfy, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2a659",
   "metadata": {},
   "source": [
    "### NCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ea8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac82303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyepo.func import NCE\n",
    "# init nce loss\n",
    "nce = NCE(optmodel, processes=8, solve_ratio=0.05, dataset=dataset_train_cost)\n",
    "\n",
    "def forwardNCE(data, reg, loss_func, grad_log):\n",
    "    # unzip data\n",
    "    x, _, w, _ = data\n",
    "    # predict\n",
    "    cp = reg(x)\n",
    "    # get gradient\n",
    "    cp.register_hook(lambda grad: grad_log.append(abs(grad.cpu().detach().numpy()).sum()))\n",
    "    # loss\n",
    "    loss = loss_func(cp, w)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "loss_log, grad_log, regret_log_trn, regret_log_val = pipeline(reg, forwardNCE, nce, lr, num_epochs, log_step,\n",
    "                                                              loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baea176",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log, grad_log, regret_log_trn, regret_log_val, num_epochs, log_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc507af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
