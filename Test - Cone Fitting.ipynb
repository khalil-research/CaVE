{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5424e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49b5424e",
    "outputId": "7ccfabbc-196d-4963-d0af-901eff1e872b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5be4e",
   "metadata": {
    "id": "53e5be4e"
   },
   "source": [
    "## Data Set and Optimization Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25d9c9",
   "metadata": {
    "id": "ed25d9c9"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyepo.model.opt import optModel\n",
    "\n",
    "\n",
    "class optDatasetConstrs(Dataset):\n",
    "    \"\"\"\n",
    "    This class is Torch Dataset for optimization problems with active constraints.\n",
    "\n",
    "    Attributes:\n",
    "        model (optModel): Optimization models\n",
    "        feats (np.ndarray): Data features\n",
    "        costs (np.ndarray): Cost vectors\n",
    "        sols (np.ndarray): Optimal solutions\n",
    "        ctrs (list(np.ndarray)): active constraints\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, feats, costs=None, sols=None):\n",
    "        \"\"\"\n",
    "        A method to create a optDataset from optModel\n",
    "\n",
    "        Args:\n",
    "            model (optModel): an instance of optModel\n",
    "            feats (np.ndarray): data features\n",
    "            costs (np.ndarray): costs of objective function\n",
    "            sols (np.ndarray): optimal solutions\n",
    "        \"\"\"\n",
    "        if not isinstance(model, optModel):\n",
    "            raise TypeError(\"arg model is not an optModel\")\n",
    "        if (costs is None) and (sols is None):\n",
    "            raise ValueError(\"At least one of 'costs' or 'sols' must be provided.\")\n",
    "        self.model = model\n",
    "        # data\n",
    "        self.feats = feats\n",
    "        # find optimal solutions and tight constraints\n",
    "        if sols is None:\n",
    "            self.costs = costs\n",
    "            self.sols, self.ctrs = self._getSols()\n",
    "        # get tight constraints\n",
    "        else:\n",
    "            self.costs = None\n",
    "            self.sols = sols\n",
    "            self.ctrs = self._getCtrs()\n",
    "\n",
    "    def _getSols(self):\n",
    "        \"\"\"\n",
    "        A method to get optimal solutions for all cost vectors\n",
    "        \"\"\"\n",
    "        sols, ctrs = [], []\n",
    "        print(\"Optimizing for optDataset...\")\n",
    "        time.sleep(1)\n",
    "        for c in tqdm(self.costs):\n",
    "            try:\n",
    "                # solve\n",
    "                sol = self._solve(c)\n",
    "                # get constrs\n",
    "                constrs = self._getBindingConstrs(self.model._model)\n",
    "            except:\n",
    "                raise ValueError(\n",
    "                    \"For optModel, the method 'solve' should return solution vector and objective value.\"\n",
    "                )\n",
    "            sols.append(sol)\n",
    "            ctrs.append(np.array(constrs))\n",
    "        return np.array(sols), ctrs\n",
    "    \n",
    "    def _getCtrs(self):\n",
    "        \"\"\"\n",
    "        A method to get the binding constraints from given solution\n",
    "        \"\"\"\n",
    "        ctrs = []\n",
    "        print(\"Obtaining constraints for optDataset...\")\n",
    "        time.sleep(1)\n",
    "        for sol in tqdm(self.sols):\n",
    "            # give sol\n",
    "            model = self._assignSol(sol)\n",
    "            # get constrs\n",
    "            constrs = self._getBindingConstrs(model)\n",
    "            ctrs.append(np.array(constrs))\n",
    "        return ctrs\n",
    "\n",
    "    def _solve(self, cost):\n",
    "        \"\"\"\n",
    "        A method to solve optimization problem to get an optimal solution with given cost\n",
    "\n",
    "        Args:\n",
    "            cost (np.ndarray): cost of objective function\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimal solution (np.ndarray) and objective value (float)\n",
    "        \"\"\"\n",
    "        self.model.setObj(cost)\n",
    "        sol, _ = self.model.solve()\n",
    "        return sol\n",
    "    \n",
    "    def _assignSol(self, sol):\n",
    "        \"\"\"\n",
    "        A method to fix model with given solution \n",
    "\n",
    "        Args:\n",
    "            sols (np.ndarray): Optimal solutions\n",
    "\n",
    "        Returns:\n",
    "            model (optModel): Optimization models\n",
    "        \"\"\"\n",
    "        # copy model\n",
    "        model = self.model.copy()\n",
    "        # fix value\n",
    "        for i, k in enumerate(self.model.x):\n",
    "            model.x[k].lb = sol[i]\n",
    "            model.x[k].ub = sol[i]\n",
    "        # set 0 obj\n",
    "        model._model.setObjective(0)\n",
    "        # solve\n",
    "        model._model.optimize()\n",
    "        return model._model\n",
    "        \n",
    "\n",
    "    def _getBindingConstrs(self, model):\n",
    "        \"\"\"\n",
    "        A method to get tight constraints with current solution\n",
    "        \n",
    "        Args:\n",
    "            model (optModel): Optimization models\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: normal vector of constraints\n",
    "        \"\"\"\n",
    "        xs = model.getVars()\n",
    "        constrs = []\n",
    "        # iterate all constraints\n",
    "        for constr in model.getConstrs():\n",
    "            # check tight constraints\n",
    "            if abs(constr.Slack) < 1e-5:\n",
    "                t_constr = []\n",
    "                # get coefficients\n",
    "                for x in xs:\n",
    "                    t_constr.append(model.getCoeff(constr, x))\n",
    "                # get coefficients in standard form\n",
    "                if constr.sense == GRB.LESS_EQUAL:\n",
    "                    # <=\n",
    "                    constrs.append(t_constr)\n",
    "                elif constr.sense == GRB.GREATER_EQUAL:\n",
    "                    # >=\n",
    "                    constrs.append([- coef for coef in t_constr])\n",
    "                elif constr.sense == GRB.EQUAL:\n",
    "                    # ==\n",
    "                    constrs.append(t_constr)\n",
    "                    constrs.append([- coef for coef in t_constr])\n",
    "                else:\n",
    "                    # invalid sense\n",
    "                    raise ValueError(\"Invalid constraint sense.\")\n",
    "        # iterate all variables\n",
    "        for i, x in enumerate(xs):\n",
    "            t_constr = [0] * len(xs)\n",
    "            # add bounds as cosnrtaints\n",
    "            if x.x <= 1e-5:\n",
    "                # x_i >= 0\n",
    "                t_constr[i] = - 1\n",
    "                constrs.append(t_constr)\n",
    "            elif x.x >= 1 - 1e-5:\n",
    "                # x_i <= 1\n",
    "                t_constr[i] = 1\n",
    "                constrs.append(t_constr)\n",
    "        return constrs\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        A method to get data size\n",
    "\n",
    "        Returns:\n",
    "            int: the number of optimization problems\n",
    "        \"\"\"\n",
    "        return len(self.feats)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        A method to retrieve data\n",
    "\n",
    "        Args:\n",
    "            index (int): data index\n",
    "\n",
    "        Returns:\n",
    "            tuple: data features (torch.tensor), costs (torch.tensor), optimal solutions (torch.tensor) and objective values (torch.tensor)\n",
    "        \"\"\"\n",
    "        if self.costs is None:\n",
    "            return (\n",
    "                torch.FloatTensor(self.feats[index]),\n",
    "                torch.FloatTensor(self.sols[index]),\n",
    "                torch.FloatTensor(self.ctrs[index])\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                torch.FloatTensor(self.feats[index]),\n",
    "                torch.FloatTensor(self.costs[index]),\n",
    "                torch.FloatTensor(self.sols[index]),\n",
    "                torch.FloatTensor(self.ctrs[index])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74959aac",
   "metadata": {
    "id": "74959aac"
   },
   "outputs": [],
   "source": [
    "import pyepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3bd4d",
   "metadata": {
    "id": "00e3bd4d"
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "grid = (2,2) # grid size\n",
    "num_data = 1000 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "e = 0.5 # noise width\n",
    "feats, costs = pyepo.data.shortestpath.genData(num_data+1000, num_feat, grid, deg, e, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073c3f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6073c3f4",
    "outputId": "e5734002-11c7-44d6-a6ba-006b39d0d4e5"
   },
   "outputs": [],
   "source": [
    "from pyepo.model.grb import shortestPathModel\n",
    "# set solver\n",
    "optmodel = shortestPathModel(grid)\n",
    "# test\n",
    "optmodel.setObj(costs[0])\n",
    "sol, obj = optmodel.solve()\n",
    "print(\"Obj: {}\".format(obj))\n",
    "for i, e in enumerate(optmodel.arcs):\n",
    "    if sol[i] > 1e-3:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e64dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac1e64dd",
    "outputId": "cfa534b0-e50f-4e05-ac72-374fe07eccf6"
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, c_train, c_test = train_test_split(feats, costs, test_size=1000, random_state=42)\n",
    "# get training and test data set\n",
    "dataset_train = optDatasetConstrs(optmodel, x_train, costs=c_train) # with binding constr\n",
    "dataset_test = pyepo.data.dataset.optDataset(optmodel, x_test, costs=c_test) # without binding constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and test data set without costs\n",
    "dataset_train = optDatasetConstrs(optmodel, x_train, sols=dataset_train.sols) # with binding constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77111dd8",
   "metadata": {
    "id": "77111dd8"
   },
   "outputs": [],
   "source": [
    "# get data loader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2da3",
   "metadata": {
    "id": "c21a2da3"
   },
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49603cb7",
   "metadata": {
    "id": "49603cb7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, (grid[0]-1)*grid[1]+(grid[1]-1)*grid[0])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6a2e2",
   "metadata": {
    "id": "8dd6a2e2"
   },
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01672965",
   "metadata": {
    "id": "01672965"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc7cac",
   "metadata": {
    "id": "0dfc7cac"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from pyepo import EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6cf5e",
   "metadata": {
    "id": "ece6cf5e"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from torch.nn import functional as F\n",
    "from pyepo import EPO\n",
    "\n",
    "class polarConeAngle(nn.Module):\n",
    "    \"\"\"\n",
    "    A autograd module for polar cone fitting loss with binary variables\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optmodel):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optmodel (optModel): an PyEPO optimization model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # optimization model\n",
    "        if not isinstance(optmodel, optModel):\n",
    "            raise TypeError(\"arg model is not an optModel\")\n",
    "        self.optmodel = optmodel\n",
    "\n",
    "    def forward(self, pred_cost, tight_ctrs, reduction=\"mean\"):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        loss = self._calLoss(pred_cost, tight_ctrs, self.optmodel)\n",
    "        # reduction\n",
    "        if reduction == \"mean\":\n",
    "            loss = torch.mean(loss)\n",
    "        elif reduction == \"sum\":\n",
    "            loss = torch.sum(loss)\n",
    "        elif reduction == \"none\":\n",
    "            loss = loss\n",
    "        else:\n",
    "            raise ValueError(\"No reduction '{}'.\".format(reduction))\n",
    "        return loss\n",
    "\n",
    "    def _calLoss(self, pred_cost, tight_ctrs, optmodel):\n",
    "        \"\"\"\n",
    "        A method to calculate loss\n",
    "        \"\"\"\n",
    "        # get device\n",
    "        device = pred_cost.device\n",
    "        # get batch size\n",
    "        batch_size = len(pred_cost)\n",
    "        # init loss\n",
    "        loss = torch.empty(batch_size).to(device)\n",
    "        # cost vectors direction\n",
    "        if optmodel.modelSense == EPO.MINIMIZE:\n",
    "            # minimize\n",
    "            pred_cost = - pred_cost\n",
    "        # constraints to numpy\n",
    "        tight_ctrs = tight_ctrs.cpu().detach().numpy()\n",
    "        for i in range(batch_size):\n",
    "            # get projection\n",
    "            p = self._getProjection(pred_cost[i], tight_ctrs[i])\n",
    "            # calculate cosine similarity\n",
    "            loss[i] = - F.cosine_similarity(pred_cost[i].unsqueeze(0), p.unsqueeze(0))\n",
    "        return loss\n",
    "\n",
    "    def _getProjection(self, cp, ctr):\n",
    "        \"\"\"\n",
    "        A method to get the projection of the vector onto the polar cone via solving a quadratic programming\n",
    "        \"\"\"\n",
    "        # ceate a model\n",
    "        m = gp.Model(\"projection\")\n",
    "        # turn off output\n",
    "        m.Params.outputFlag = 0\n",
    "        # varibles\n",
    "        p = m.addVars(len(cp), name=\"x\", lb=-GRB.INFINITY)\n",
    "        λ = m.addVars(len(ctr), name=\"lambda\")\n",
    "        # onjective function\n",
    "        obj = gp.quicksum((cp[i].item() - p[i]) ** 2 for i in range(len(cp)))\n",
    "        m.setObjective(obj, GRB.MINIMIZE)\n",
    "        # constraints\n",
    "        for i in range(len(cp)):\n",
    "            m.addConstr(gp.quicksum(ctr[j,i] * λ[j] for j in range(len(ctr))) == p[i])\n",
    "        # focus on numeric problem\n",
    "        m.Params.NumericFocus = 3\n",
    "        # solve\n",
    "        m.update()\n",
    "        m.optimize()\n",
    "        # get solutions\n",
    "        λ_val = np.array([λ[i].x for i in λ])\n",
    "        # normalize\n",
    "        λ_norm = λ_val / np.linalg.norm(λ_val)\n",
    "        # get normalized projection\n",
    "        proj = torch.FloatTensor(λ_norm @ ctr)\n",
    "        return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67660513",
   "metadata": {
    "id": "67660513"
   },
   "outputs": [],
   "source": [
    "# init loss\n",
    "pca_loss = polarConeAngle(optmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fb9a6",
   "metadata": {
    "id": "f71fb9a6"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c283113",
   "metadata": {
    "id": "5c283113"
   },
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(reg.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c332205",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c332205",
    "outputId": "b01697bd-80f7-4f58-eb97-35b5276c0ff1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "log_step = 2\n",
    "loss_log, regret_log = [], [pyepo.metric.regret(reg, optmodel, loader_test)]\n",
    "for epoch in range(num_epochs):\n",
    "    for data in loader_train:\n",
    "        x, w, t_ctr = data\n",
    "        # forward pass\n",
    "        cp = reg(x)\n",
    "        loss = pca_loss(cp, t_ctr)\n",
    "        #loss = torch.sum(cp)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_log.append(loss.item())\n",
    "    if (epoch+1) % log_step == 1:\n",
    "        # regret\n",
    "        regret = pyepo.metric.regret(reg, optmodel, loader_test)\n",
    "        regret_log.append(regret)\n",
    "        print(\"Epoch {:3}, Loss: {:8.4f}, Regret: {:7.4f}%\".format(epoch, loss.item(), regret*100))\n",
    "        # print gradients\n",
    "        #for name, param in reg.named_parameters():\n",
    "        #    if param.requires_grad:\n",
    "        #        print(f\"Gradient of {name}: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91efbbd",
   "metadata": {
    "id": "f91efbbd"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ca51c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "dc6ca51c",
    "outputId": "cb858940-6b51-485d-a90f-a04a9d7a94e5"
   },
   "outputs": [],
   "source": [
    "# draw plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(loss_log, color=\"c\", lw=2)\n",
    "plt.xticks(fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xlabel(\"Iters\", fontsize=36)\n",
    "plt.ylabel(\"Loss\", fontsize=36)\n",
    "plt.title(\"Learning Curve\", fontsize=36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37750c29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "37750c29",
    "outputId": "40815670-3f2b-4ae0-8a9c-dc498373539f"
   },
   "outputs": [],
   "source": [
    "# draw plot\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "plt.plot(range(0, num_epochs+1, log_step), regret_log, color=\"royalblue\", ls=\"--\", alpha=0.7, lw=5, label=\"Regret\")\n",
    "plt.xticks(range(0, num_epochs+1, log_step), fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xlabel(\"Epoch\", fontsize=36)\n",
    "plt.ylabel(\"Loss\", fontsize=36)\n",
    "plt.title(\"Learning Curve\", fontsize=36)\n",
    "plt.legend(fontsize=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb666a9",
   "metadata": {
    "id": "adb666a9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
