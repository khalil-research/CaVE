{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e5be4e",
   "metadata": {},
   "source": [
    "## Data Set and Optimization Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74959aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    }
   ],
   "source": [
    "import pyepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e3bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "grid = (2,2) # grid size\n",
    "num_data = 1000 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "e = 0.5 # noise width\n",
    "feats, costs = pyepo.data.shortestpath.genData(num_data+1000, num_feat, grid, deg, e, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6073c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-01\n",
      "Obj: 0.5009689961416153\n",
      "(0, 2)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "from pyepo.model.grb import shortestPathModel\n",
    "# set solver\n",
    "optmodel = shortestPathModel(grid)\n",
    "# test\n",
    "optmodel.setObj(costs[0])\n",
    "sol, obj = optmodel.solve()\n",
    "print(\"Obj: {}\".format(obj))\n",
    "for i, e in enumerate(optmodel.arcs):\n",
    "    if sol[i] > 1e-3:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1e64dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4898.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5047.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, c_train, c_test = train_test_split(feats, costs, test_size=1000, random_state=42)\n",
    "# get training and test data set\n",
    "dataset_train = pyepo.data.dataset.optDataset(optmodel, x_train, c_train)\n",
    "dataset_test = pyepo.data.dataset.optDataset(optmodel, x_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77111dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2da3",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49603cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, (grid[0]-1)*grid[1]+(grid[1]-1)*grid[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd6a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01672965",
   "metadata": {},
   "source": [
    "## Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dfc7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from pyepo import EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ece6cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class polarConeAngle(nn.Module):\n",
    "    \"\"\"\n",
    "    A autograd module for polar cone fitting loss with binary variables\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, pred_cost, true_sol):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        loss = polarConeAngleFunc.apply(pred_cost, true_sol, optmodel)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "class polarConeAngleFunc(Function):\n",
    "    \"\"\"\n",
    "    A autograd function for polar cone fitting loss with binary variables\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, pred_cost, true_sol, optmodel):\n",
    "        # get device\n",
    "        device = pred_cost.device\n",
    "        # get batch size\n",
    "        batch_size = len(pred_cost)\n",
    "        # init loss\n",
    "        loss = torch.empty(batch_size).to(device)\n",
    "        for i in range(batch_size):\n",
    "            # check if the vector in the cone\n",
    "            if optmodel.modelSense == EPO.MINIMIZE:\n",
    "                inside = torch.equal(pred_cost[i] <= 0, true_sol[i].type(torch.BoolTensor))\n",
    "            if optmodel.modelSense == EPO.MAXIMIZE:\n",
    "                inside = torch.equal(pred_cost[i] >= 0, true_sol[i].type(torch.BoolTensor))\n",
    "            # zero loss if inside\n",
    "            if inside:\n",
    "                loss[i]= 0\n",
    "            else:\n",
    "                u = getProjection(pred_cost[i], true_sol[i], optmodel)\n",
    "        print(loss)\n",
    "\n",
    "        \n",
    "def getProjection(cp, w, optmodel):\n",
    "    \"\"\"\n",
    "    A function to get the projection of the vector onto the polar cone via solving a quadratic programming\n",
    "    \"\"\"\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"shortest path\")\n",
    "    # turn off output\n",
    "    m.Params.outputFlag = 0\n",
    "    # bounds for constraints: vector on hyperquadrant\n",
    "    lb, ub = []\n",
    "    for wi in w:\n",
    "        if optmodel.modelSense == EPO.MINIMIZE:\n",
    "            if wi < 1e-5:\n",
    "                pass\n",
    "            else\n",
    "                pass\n",
    "        if optmodel.modelSense == EPO.MAXIMIZE:\n",
    "            if wi < 1e-5:\n",
    "                lb.append(-GRB.INFINITY)\n",
    "                ub.append(0)\n",
    "            else\n",
    "                pass\n",
    "    # varibles\n",
    "    p = m.addVars(len(cp), name=\"x\", lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    # onjective function\n",
    "    obj = gp.quicksum((cp[i].item() - p[i]) ** 2 for i in range(len(cp)))\n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "    # constraints: vector on hyperquadrant\n",
    "    for i in (w < 1e-5).nonzero()[:,0].tolist():\n",
    "        print(i)\n",
    "    # solve\n",
    "    m.update()\n",
    "    m.optimize()\n",
    "    # get solutions\n",
    "    proj = [p[k].x for k in range(len(cp))]\n",
    "    print(cp)\n",
    "    print(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67660513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init loss\n",
    "pca_loss = polarConeAngle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd2d6b",
   "metadata": {},
   "source": [
    "## Warning: Numerical Issue for Arcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a00453bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5708, 0.0000,    nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.acos(torch.tensor([0, 1, 1+1e8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fb9a6",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c332205",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "tensor([ 0.0278,  1.1744, -1.6073, -0.5694], requires_grad=True)\n",
      "[0.027828067541122437, 1.1744039058685303, -1.607252597808838, -0.5694019794464111]\n",
      "0\n",
      "2\n",
      "tensor([ 0.0379,  0.5856, -0.5676,  0.1112], requires_grad=True)\n",
      "[0.03790569305419922, 0.5855547785758972, -0.5676383972167969, 0.11117341369390488]\n",
      "0\n",
      "2\n",
      "tensor([-0.6318,  0.9266, -0.9418, -0.5327], requires_grad=True)\n",
      "[-0.6318060159683228, 0.9266294836997986, -0.9417837262153625, -0.532746434211731]\n",
      "1\n",
      "3\n",
      "tensor([-0.7686,  0.0114,  0.4463,  0.0773], requires_grad=True)\n",
      "[-0.7685568332672119, 0.011368781328201294, 0.4462822675704956, 0.07725083827972412]\n",
      "0\n",
      "2\n",
      "tensor([0.1785, 0.1864, 0.4608, 0.4165], requires_grad=True)\n",
      "[0.17852172255516052, 0.18637701869010925, 0.4608280658721924, 0.4164833128452301]\n",
      "1\n",
      "3\n",
      "tensor([-0.8415,  0.4828, -0.7292, -0.2009], requires_grad=True)\n",
      "[-0.8414782285690308, 0.482845664024353, -0.7291617393493652, -0.20090869069099426]\n",
      "0\n",
      "2\n",
      "tensor([ 0.6891,  1.1526, -0.3066, -0.6096], requires_grad=True)\n",
      "[0.6891434192657471, 1.1525806188583374, -0.30663782358169556, -0.6095832586288452]\n",
      "1\n",
      "3\n",
      "tensor([-0.3061,  0.5621,  0.4223, -0.4028], requires_grad=True)\n",
      "[-0.3061484098434448, 0.5620811581611633, 0.4222759008407593, -0.4028487205505371]\n",
      "0\n",
      "2\n",
      "tensor([ 0.0033,  0.3765, -0.2715,  0.3906], requires_grad=True)\n",
      "[0.0032715201377868652, 0.37648653984069824, -0.2714838683605194, 0.39061644673347473]\n",
      "1\n",
      "3\n",
      "tensor([-0.8984,  0.4256,  0.6473, -0.4179], requires_grad=True)\n",
      "[-0.8983976244926453, 0.4255679249763489, 0.6472889184951782, -0.4178929030895233]\n",
      "0\n",
      "2\n",
      "tensor([-0.5726,  0.1043,  0.5641,  0.0023], requires_grad=True)\n",
      "[-0.5726268291473389, 0.10427320003509521, 0.5641083121299744, 0.0023275911808013916]\n",
      "1\n",
      "3\n",
      "tensor([-1.1494, -0.2773,  0.2957,  0.3683], requires_grad=True)\n",
      "[-1.1493631601333618, -0.2772507667541504, 0.29567378759384155, 0.3683415353298187]\n",
      "0\n",
      "2\n",
      "tensor([-0.9329, -0.2333,  0.3314,  0.4468], requires_grad=True)\n",
      "[-0.9329437017440796, -0.2332974076271057, 0.33139127492904663, 0.4467633068561554]\n",
      "1\n",
      "3\n",
      "tensor([-0.3531,  1.1361, -1.8194, -0.5334], requires_grad=True)\n",
      "[-0.35305359959602356, 1.136080265045166, -1.8194222450256348, -0.5334112644195557]\n",
      "0\n",
      "2\n",
      "tensor([ 0.5852,  1.0808,  0.1904, -0.8772], requires_grad=True)\n",
      "[0.5851913690567017, 1.0808025598526, 0.19037342071533203, -0.8772348165512085]\n",
      "1\n",
      "3\n",
      "tensor([-1.0626,  0.7622, -0.7032, -0.4535], requires_grad=True)\n",
      "[-1.0626221895217896, 0.762179970741272, -0.703212320804596, -0.45348820090293884]\n",
      "1\n",
      "3\n",
      "tensor([-0.8248,  0.4031, -0.3053, -0.2310], requires_grad=True)\n",
      "[-0.8247954845428467, 0.4031433165073395, -0.30525463819503784, -0.23095202445983887]\n",
      "0\n",
      "2\n",
      "tensor([-0.4542,  0.9835, -0.9197, -0.9566], requires_grad=True)\n",
      "[-0.45419251918792725, 0.9835414290428162, -0.9196594953536987, -0.956627607345581]\n",
      "0\n",
      "2\n",
      "tensor([-1.7129,  0.1257, -0.0588, -0.4687], requires_grad=True)\n",
      "[-1.7128826379776, 0.12572306394577026, -0.0587770938873291, -0.4687463939189911]\n",
      "1\n",
      "3\n",
      "tensor([ 0.0501,  0.3326, -0.2230,  0.4417], requires_grad=True)\n",
      "[0.05007767677307129, 0.3325869143009186, -0.22299833595752716, 0.4417014420032501]\n",
      "1\n",
      "3\n",
      "tensor([-0.2133, -0.0092, -0.1163,  0.7597], requires_grad=True)\n",
      "[-0.21330246329307556, -0.009184271097183228, -0.11632482707500458, 0.7596942186355591]\n",
      "0\n",
      "2\n",
      "tensor([-0.2261,  0.3431, -0.4193,  0.2786], requires_grad=True)\n",
      "[-0.22611665725708008, 0.34312570095062256, -0.4192958474159241, 0.2786436676979065]\n",
      "1\n",
      "3\n",
      "tensor([ 0.3827,  0.4783, -0.9411,  0.5040], requires_grad=True)\n",
      "[0.3826685845851898, 0.47831863164901733, -0.9411454796791077, 0.5040099620819092]\n",
      "0\n",
      "2\n",
      "tensor([-0.7458,  1.0192, -0.4141, -1.1164], requires_grad=True)\n",
      "[-0.7458006143569946, 1.0192365646362305, -0.41412588953971863, -1.1163520812988281]\n",
      "1\n",
      "3\n",
      "tensor([-0.2704, -0.0292,  0.5405,  0.5873], requires_grad=True)\n",
      "[-0.2704448401927948, -0.029155224561691284, 0.5404704213142395, 0.5873037576675415]\n",
      "0\n",
      "2\n",
      "tensor([-0.3813, -0.2009, -0.5168,  0.9510], requires_grad=True)\n",
      "[-0.38130685687065125, -0.20085501670837402, -0.5168052315711975, 0.9509850740432739]\n",
      "1\n",
      "3\n",
      "tensor([ 0.7994,  1.0331, -0.9819,  0.1649], requires_grad=True)\n",
      "[0.7994130849838257, 1.0330593585968018, -0.9818791747093201, 0.16488273441791534]\n",
      "1\n",
      "3\n",
      "tensor([-0.2022, -0.3172, -0.4474,  1.5979], requires_grad=True)\n",
      "[-0.20224058628082275, -0.3172319531440735, -0.44737428426742554, 1.5978543758392334]\n",
      "0\n",
      "2\n",
      "tensor([-0.8811,  0.2274, -0.3278,  0.1438], requires_grad=True)\n",
      "[-0.8810759782791138, 0.2273859977722168, -0.3278118968009949, 0.14382687211036682]\n",
      "tensor([5.1167e+26, 4.7364e-43, 1.4013e-45, 0.0000e+00, 7.0065e-45, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.0065e-45, 0.0000e+00, 9.1844e-41, 0.0000e+00,\n",
      "        2.2960e-41, 4.1478e-43])\n"
     ]
    }
   ],
   "source": [
    "for data in loader_train:\n",
    "    x, c, w, z = data\n",
    "    # forward pass\n",
    "    cp = reg(x)\n",
    "    loss = pca_loss(cp, w)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041275ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
