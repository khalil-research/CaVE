{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e5be4e",
   "metadata": {},
   "source": [
    "## Data Set and Optimization Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed25d9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyepo.model.opt import optModel\n",
    "\n",
    "\n",
    "class optDatasetConstrs(Dataset):\n",
    "    \"\"\"\n",
    "    This class is Torch Dataset for optimization problems with active constraints.\n",
    "\n",
    "    Attributes:\n",
    "        model (optModel): Optimization models\n",
    "        feats (np.ndarray): Data features\n",
    "        costs (np.ndarray): Cost vectors\n",
    "        sols (np.ndarray): Optimal solutions\n",
    "        objs (np.ndarray): Optimal objective values\n",
    "        ctrs (list(np.ndarray)): active constraints\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, feats, costs):\n",
    "        \"\"\"\n",
    "        A method to create a optDataset from optModel\n",
    "\n",
    "        Args:\n",
    "            model (optModel): an instance of optModel\n",
    "            feats (np.ndarray): data features\n",
    "            costs (np.ndarray): costs of objective function\n",
    "        \"\"\"\n",
    "        if not isinstance(model, optModel):\n",
    "            raise TypeError(\"arg model is not an optModel\")\n",
    "        self.model = model\n",
    "        # data\n",
    "        self.feats = feats\n",
    "        self.costs = costs\n",
    "        # find optimal solutions\n",
    "        self.sols, self.objs, self.ctrs = self._getSols()\n",
    "\n",
    "    def _getSols(self):\n",
    "        \"\"\"\n",
    "        A method to get optimal solutions for all cost vectors\n",
    "        \"\"\"\n",
    "        sols, objs, ctrs = [], [], []\n",
    "        print(\"Optimizing for optDataset...\")\n",
    "        time.sleep(1)\n",
    "        for c in tqdm(self.costs):\n",
    "            try:\n",
    "                sol, obj = self._solve(c)\n",
    "                constrs = self._getActiveConstrs()\n",
    "            except:\n",
    "                raise ValueError(\n",
    "                    \"For optModel, the method 'solve' should return solution vector and objective value.\"\n",
    "                )\n",
    "            sols.append(sol)\n",
    "            objs.append([obj])\n",
    "            ctrs.append(np.array(constrs))\n",
    "        return np.array(sols), np.array(objs), ctrs\n",
    "\n",
    "    def _solve(self, cost):\n",
    "        \"\"\"\n",
    "        A method to solve optimization problem to get an optimal solution with given cost\n",
    "\n",
    "        Args:\n",
    "            cost (np.ndarray): cost of objective function\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimal solution (np.ndarray) and objective value (float)\n",
    "        \"\"\"\n",
    "        self.model.setObj(cost)\n",
    "        sol, obj = self.model.solve()\n",
    "        return sol, obj\n",
    "    \n",
    "    def _getActiveConstrs(self):\n",
    "        \"\"\"\n",
    "        A method to get active constraints with current optimal solution\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: normal vector of constraints\n",
    "        \"\"\"\n",
    "        constrs = []\n",
    "        # iterate all constraints\n",
    "        for constr in self.model._model.getConstrs():\n",
    "            # check tight constraints\n",
    "            if abs(constr.Slack) < 1e-5:\n",
    "                t_constr = []\n",
    "                # get coefficients\n",
    "                for i in self.model.x:\n",
    "                    t_constr.append(self.model._model.getCoeff(constr, self.model.x[i]))\n",
    "                # get coefficients in standard form\n",
    "                if constr.sense == GRB.LESS_EQUAL:\n",
    "                    # <=\n",
    "                    constrs.append(t_constr)\n",
    "                elif constr.sense == GRB.GREATER_EQUAL:\n",
    "                    # >=\n",
    "                    constrs.append([- coef for coef in t_constr])\n",
    "                elif constr.sense == GRB.EQUAL:\n",
    "                    # ==\n",
    "                    constrs.append(t_constr)\n",
    "                    constrs.append([- coef for coef in t_constr])\n",
    "                else:\n",
    "                    # invalid sense\n",
    "                    raise ValueError(\"Invalid constraint sense.\")\n",
    "        # iterate all constraints\n",
    "        for i, v in enumerate(self.model._model.getVars()):\n",
    "            t_constr = [0] * len(self.model.x)\n",
    "            # check variables on bounds\n",
    "            if v.x <= 1e-5:\n",
    "                # x_i >= 0\n",
    "                t_constr[i] = -1\n",
    "                constrs.append(t_constr)\n",
    "            elif v.x >= 1 - 1e-5:\n",
    "                # x_i <= 1\n",
    "                t_constr[i] = 1\n",
    "                constrs.append(t_constr)\n",
    "        return constrs\n",
    "                \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        A method to get data size\n",
    "\n",
    "        Returns:\n",
    "            int: the number of optimization problems\n",
    "        \"\"\"\n",
    "        return len(self.costs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        A method to retrieve data\n",
    "\n",
    "        Args:\n",
    "            index (int): data index\n",
    "\n",
    "        Returns:\n",
    "            tuple: data features (torch.tensor), costs (torch.tensor), optimal solutions (torch.tensor) and objective values (torch.tensor)\n",
    "        \"\"\"\n",
    "        return (\n",
    "            torch.FloatTensor(self.feats[index]),\n",
    "            torch.FloatTensor(self.costs[index]),\n",
    "            torch.FloatTensor(self.sols[index]),\n",
    "            torch.FloatTensor(self.objs[index]),\n",
    "            torch.FloatTensor(self.ctrs[index])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74959aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e3bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "grid = (2,3) # grid size\n",
    "num_data = 1000 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "e = 0.5 # noise width\n",
    "feats, costs = pyepo.data.shortestpath.genData(num_data+1000, num_feat, grid, deg, e, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6073c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-01\n",
      "Obj: 1.26477683707676\n",
      "(0, 3)\n",
      "(3, 6)\n",
      "(6, 7)\n",
      "(7, 8)\n"
     ]
    }
   ],
   "source": [
    "from pyepo.model.grb import shortestPathModel\n",
    "# set solver\n",
    "optmodel = shortestPathModel(grid)\n",
    "# test\n",
    "optmodel.setObj(costs[0])\n",
    "sol, obj = optmodel.solve()\n",
    "print(\"Obj: {}\".format(obj))\n",
    "for i, e in enumerate(optmodel.arcs):\n",
    "    if sol[i] > 1e-3:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1e64dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1777.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1835.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, c_train, c_test = train_test_split(feats, costs, test_size=1000, random_state=42)\n",
    "# get training and test data set\n",
    "dataset_train = optDatasetConstrs(optmodel, x_train, c_train)\n",
    "dataset_test = optDatasetConstrs(optmodel, x_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77111dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2da3",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49603cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, (grid[0]-1)*grid[1]+(grid[1]-1)*grid[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dd6a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01672965",
   "metadata": {},
   "source": [
    "## Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dfc7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from pyepo import EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ece6cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class polarConeAngle(nn.Module):\n",
    "    \"\"\"\n",
    "    A autograd module for polar cone fitting loss with binary variables\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, pred_cost, tight_ctrs):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        loss = polarConeAngleFunc.apply(pred_cost, tight_ctrs)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "class polarConeAngleFunc(Function):\n",
    "    \"\"\"\n",
    "    A autograd function for polar cone fitting loss with binary variables\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, pred_cost, tight_ctrs):\n",
    "        # get device\n",
    "        device = pred_cost.device\n",
    "        # get batch size\n",
    "        batch_size = len(pred_cost)\n",
    "        # init loss\n",
    "        loss = torch.empty(batch_size).to(device)\n",
    "        # constraints to numpy\n",
    "        tight_ctrs = tight_ctrs.cpu().detach().numpy()\n",
    "        for i in range(batch_size):\n",
    "            # get projection\n",
    "            p = getProjection(pred_cost[i], tight_ctrs[i])\n",
    "            # calculate cosine similarity\n",
    "            loss[i] = - F.cosine_similarity(pred_cost[i].unsqueeze(0), p.unsqueeze(0))\n",
    "            print(i, loss[i].item(), p.detach().numpy(), pred_cost[i].detach().numpy())\n",
    "            break\n",
    "        return loss\n",
    "\n",
    "        \n",
    "def getProjection(cp, ctr):\n",
    "    \"\"\"\n",
    "    A function to get the projection of the vector onto the polar cone via solving a quadratic programming\n",
    "    \"\"\"\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"shortest path\")\n",
    "    # turn off output\n",
    "    m.Params.outputFlag = 0\n",
    "    # varibles\n",
    "    p = m.addVars(len(cp), name=\"x\", lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    λ = m.addVars(len(ctr), name=\"lambda\")\n",
    "    # onjective function\n",
    "    obj = gp.quicksum((- cp[i].item() - p[i]) ** 2 for i in range(len(cp)))\n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "    # constraints\n",
    "    print(ctr)\n",
    "    for i in range(len(cp)):\n",
    "        m.addConstr(gp.quicksum(ctr[j,i] * λ[j] for j in range(len(ctr))) == p[i])\n",
    "    # solve\n",
    "    m.update()\n",
    "    m.optimize()\n",
    "    # get solutions\n",
    "    proj = torch.FloatTensor([p[i].x for i in range(len(cp))])\n",
    "    print(λ)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67660513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init loss\n",
    "pca_loss = polarConeAngle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd2d6b",
   "metadata": {},
   "source": [
    "## Warning: Numerical Issue for Arcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a00453bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5708, 0.0000,    nan])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.acos(torch.tensor([0, 1, 1+1e8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fb9a6",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c332205",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1. -0.  1. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [ 1. -1.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  1. -0.  1. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [ 0.  1.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-0. -1. -0. -0.  1. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [ 0.  0.  1.  0.  0. -1.  0. -1.  0.  0.  0.  0.]\n",
      " [-0. -0. -1. -0. -0.  1. -0.  1. -0. -0. -0. -0.]\n",
      " [ 0.  0.  0.  1.  0.  1. -1.  0. -1.  0.  0.  0.]\n",
      " [-0. -0. -0. -1. -0. -1.  1. -0.  1. -0. -0. -0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  1.  0.  0. -1.  0.  0.]\n",
      " [-0. -0. -0. -0. -1. -0. -1. -0. -0.  1. -0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0. -1.  0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -1. -0. -0.  1. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1. -1.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -1. -0. -1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -1. -0. -1.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "{0: <gurobi.Var lambda[0] (value 0.0)>, 1: <gurobi.Var lambda[1] (value 0.25999802581430187)>, 2: <gurobi.Var lambda[2] (value 0.3608649541014948)>, 3: <gurobi.Var lambda[3] (value 0.0)>, 4: <gurobi.Var lambda[4] (value 0.65151866906722)>, 5: <gurobi.Var lambda[5] (value 0.0)>, 6: <gurobi.Var lambda[6] (value 0.0)>, 7: <gurobi.Var lambda[7] (value 0.35839732641643884)>, 8: <gurobi.Var lambda[8] (value 0.37638452321706556)>, 9: <gurobi.Var lambda[9] (value 0.0)>, 10: <gurobi.Var lambda[10] (value 0.26535562328071505)>, 11: <gurobi.Var lambda[11] (value 0.0)>, 12: <gurobi.Var lambda[12] (value 0.0)>, 13: <gurobi.Var lambda[13] (value 0.24259124276370547)>, 14: <gurobi.Var lambda[14] (value 0.0)>, 15: <gurobi.Var lambda[15] (value 0.0)>, 16: <gurobi.Var lambda[16] (value 0.750670250016007)>, 17: <gurobi.Var lambda[17] (value 0.0)>, 18: <gurobi.Var lambda[18] (value 0.0)>, 19: <gurobi.Var lambda[19] (value 0.0)>, 20: <gurobi.Var lambda[20] (value 0.0)>, 21: <gurobi.Var lambda[21] (value 6.129142332556015e-13)>, 22: <gurobi.Var lambda[22] (value 7.414526770332941e-10)>, 23: <gurobi.Var lambda[23] (value 1.1755620124451476)>, 24: <gurobi.Var lambda[24] (value 6.25735574466546e-13)>, 25: <gurobi.Var lambda[25] (value -5.0834336740024355e-14)>, 26: <gurobi.Var lambda[26] (value 0.6879334184636337)>, 27: <gurobi.Var lambda[27] (value -5.551115123125783e-17)>, 28: <gurobi.Var lambda[28] (value 0.0)>, 29: <gurobi.Var lambda[29] (value 6.007416786246722e-13)>}\n",
      "0 -0.6430034041404724 [ 0.62086296  0.2906537  -0.0983993   0.01551957 -0.38616306 -0.44078016\n",
      " -0.1110289   0.11580608 -1.064318    0.48531464  0.24259125  0.75067025] [ 1.347976    0.36800003 -0.8255123   0.66528624 -0.30881673 -0.44078016\n",
      "  0.5387378  -0.6113069  -1.064318    1.2124276  -0.48452175  0.02355726]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.] [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n",
      "2.330030679702759 2.3300307989120483\n"
     ]
    }
   ],
   "source": [
    "for data in loader_train:\n",
    "    x, c, w, z, t_ctr = data\n",
    "    # forward pass\n",
    "    cp = reg(x)\n",
    "    loss = pca_loss(cp, t_ctr)\n",
    "    # check sol\n",
    "    for i in range(len(cp)):\n",
    "        optmodel.setObj(costs[0])\n",
    "        wpi, zpi = optmodel.solve()\n",
    "        print(w[i].detach().numpy(), wpi)\n",
    "        print(z[i].item(), c[i].detach().numpy()@wpi)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f1a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
