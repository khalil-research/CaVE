{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7f8517",
   "metadata": {},
   "source": [
    "## Optimization Solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f154e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from pyepo.model.grb import optGrbModel\n",
    "\n",
    "class myModel(optGrbModel):\n",
    "    def _getModel(self):\n",
    "        \"\"\"\n",
    "        A method to build Gurobi model\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimization model and variables\n",
    "        \"\"\"\n",
    "        # ceate a model\n",
    "        m = gp.Model(\"Simple Model\")\n",
    "        # varibles\n",
    "        x = m.addVars([1,2], name=\"x\", vtype=GRB.BINARY)\n",
    "        # sense\n",
    "        m.modelSense = GRB.MAXIMIZE\n",
    "        # constraints\n",
    "        m.addConstr(2 * x[1] + 2 * x[2] <= 3)\n",
    "        return m, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55868436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-01\n",
      "Obj: 1.0\n",
      "x_1 = -0.00, x_2 = 1.00\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "optmodel = myModel()\n",
    "optmodel.setObj([0,1])\n",
    "sol, obj = optmodel.solve()\n",
    "print(\"Obj: {}\".format(obj))\n",
    "print(\"x_1 = {:.2f}, x_2 = {:.2f}\".format(sol[0], sol[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5be4e",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed25d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyepo.model.opt import optModel\n",
    "\n",
    "\n",
    "class optDatasetConstrs(Dataset):\n",
    "    \"\"\"\n",
    "    This class is Torch Dataset for optimization problems with active constraints.\n",
    "\n",
    "    Attributes:\n",
    "        model (optModel): Optimization models\n",
    "        feats (np.ndarray): Data features\n",
    "        costs (np.ndarray): Cost vectors\n",
    "        sols (np.ndarray): Optimal solutions\n",
    "        objs (np.ndarray): Optimal objective values\n",
    "        ctrs (list(np.ndarray)): active constraints\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, feats, costs):\n",
    "        \"\"\"\n",
    "        A method to create a optDataset from optModel\n",
    "\n",
    "        Args:\n",
    "            model (optModel): an instance of optModel\n",
    "            feats (np.ndarray): data features\n",
    "            costs (np.ndarray): costs of objective function\n",
    "        \"\"\"\n",
    "        if not isinstance(model, optModel):\n",
    "            raise TypeError(\"arg model is not an optModel\")\n",
    "        self.model = model\n",
    "        # data\n",
    "        self.feats = feats\n",
    "        self.costs = costs\n",
    "        # find optimal solutions\n",
    "        self.sols, self.objs, self.ctrs = self._getSols()\n",
    "\n",
    "    def _getSols(self):\n",
    "        \"\"\"\n",
    "        A method to get optimal solutions for all cost vectors\n",
    "        \"\"\"\n",
    "        sols, objs, ctrs = [], [], []\n",
    "        print(\"Optimizing for optDataset...\")\n",
    "        time.sleep(1)\n",
    "        for c in tqdm(self.costs):\n",
    "            try:\n",
    "                sol, obj = self._solve(c)\n",
    "                constrs = self._getBindingConstrs()\n",
    "            except:\n",
    "                raise ValueError(\n",
    "                    \"For optModel, the method 'solve' should return solution vector and objective value.\"\n",
    "                )\n",
    "            sols.append(sol)\n",
    "            objs.append([obj])\n",
    "            ctrs.append(np.array(constrs))\n",
    "        return np.array(sols), np.array(objs), ctrs\n",
    "\n",
    "    def _solve(self, cost):\n",
    "        \"\"\"\n",
    "        A method to solve optimization problem to get an optimal solution with given cost\n",
    "\n",
    "        Args:\n",
    "            cost (np.ndarray): cost of objective function\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimal solution (np.ndarray) and objective value (float)\n",
    "        \"\"\"\n",
    "        self.model.setObj(cost)\n",
    "        sol, obj = self.model.solve()\n",
    "        return sol, obj\n",
    "    \n",
    "    def _getBindingConstrs(self):\n",
    "        \"\"\"\n",
    "        A method to get active constraints with current optimal solution\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: normal vector of constraints\n",
    "        \"\"\"\n",
    "        constrs = []\n",
    "        # iterate all constraints\n",
    "        for constr in self.model._model.getConstrs():\n",
    "            # check tight constraints\n",
    "            if abs(constr.Slack) < 1e-5:\n",
    "                t_constr = []\n",
    "                # get coefficients\n",
    "                for i in self.model.x:\n",
    "                    t_constr.append(self.model._model.getCoeff(constr, self.model.x[i]))\n",
    "                # get coefficients in standard form\n",
    "                if constr.sense == GRB.LESS_EQUAL:\n",
    "                    # <=\n",
    "                    constrs.append(t_constr)\n",
    "                elif constr.sense == GRB.GREATER_EQUAL:\n",
    "                    # >=\n",
    "                    constrs.append([- coef for coef in t_constr])\n",
    "                elif constr.sense == GRB.EQUAL:\n",
    "                    # ==\n",
    "                    constrs.append(t_constr)\n",
    "                    constrs.append([- coef for coef in t_constr])\n",
    "                else:\n",
    "                    # invalid sense\n",
    "                    raise ValueError(\"Invalid constraint sense.\")\n",
    "        # iterate all constraints\n",
    "        for i, v in enumerate(self.model._model.getVars()):\n",
    "            t_constr = [0] * len(self.model.x)\n",
    "            # check variables on bounds\n",
    "            if v.x <= 1e-5:\n",
    "                # x_i >= 0\n",
    "                t_constr[i] = -1\n",
    "                constrs.append(t_constr)\n",
    "            elif v.x >= 1 - 1e-5:\n",
    "                # x_i <= 1\n",
    "                t_constr[i] = 1\n",
    "                constrs.append(t_constr)\n",
    "        return constrs\n",
    "                \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        A method to get data size\n",
    "\n",
    "        Returns:\n",
    "            int: the number of optimization problems\n",
    "        \"\"\"\n",
    "        return len(self.costs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        A method to retrieve data\n",
    "\n",
    "        Args:\n",
    "            index (int): data index\n",
    "\n",
    "        Returns:\n",
    "            tuple: data features (torch.tensor), costs (torch.tensor), optimal solutions (torch.tensor) and objective values (torch.tensor)\n",
    "        \"\"\"\n",
    "        return (\n",
    "            torch.FloatTensor(self.feats[index]),\n",
    "            torch.FloatTensor(self.costs[index]),\n",
    "            torch.FloatTensor(self.sols[index]),\n",
    "            torch.FloatTensor(self.objs[index]),\n",
    "            torch.FloatTensor(self.ctrs[index])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74959aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e3bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data from shortest path\n",
    "grid = (2,2) # grid size\n",
    "num_data = 1000 # number of training data\n",
    "num_feat = 5 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "e = 0.5 # noise width\n",
    "feats, costs = pyepo.data.shortestpath.genData(num_data+1000, num_feat, grid, deg, e, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69499e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep 2 vars\n",
    "costs = costs[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1e64dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4660.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4803.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, c_train, c_test = train_test_split(feats, costs, test_size=1000, random_state=42)\n",
    "# get training and test data set\n",
    "dataset_train = optDatasetConstrs(optmodel, x_train, c_train)\n",
    "dataset_test = optDatasetConstrs(optmodel, x_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77111dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2da3",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49603cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# build linear model\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_feat, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd6a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01672965",
   "metadata": {},
   "source": [
    "## Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece6cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from torch.nn import functional as F\n",
    "from pyepo import EPO\n",
    "\n",
    "class polarConeAngle(nn.Module):\n",
    "    \"\"\"\n",
    "    A autograd module for polar cone fitting loss with binary variables\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optmodel):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optmodel (optModel): an PyEPO optimization model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # optimization model\n",
    "        if not isinstance(optmodel, optModel):\n",
    "            raise TypeError(\"arg model is not an optModel\")\n",
    "        self.optmodel = optmodel\n",
    "    \n",
    "    def forward(self, pred_cost, tight_ctrs):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        loss = polarConeAngleFunc.apply(pred_cost, tight_ctrs, self.optmodel)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "class polarConeAngleFunc(Function):\n",
    "    \"\"\"\n",
    "    A autograd function for polar cone fitting loss with binary variables\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, pred_cost, tight_ctrs, optmodel):\n",
    "        # get device\n",
    "        device = pred_cost.device\n",
    "        # get batch size\n",
    "        batch_size = len(pred_cost)\n",
    "        # init loss\n",
    "        loss = torch.empty(batch_size).to(device)\n",
    "        # constraints to numpy\n",
    "        tight_ctrs = tight_ctrs.cpu().detach().numpy()\n",
    "        for i in range(batch_size):\n",
    "            # get projection\n",
    "            if optmodel.modelSense == EPO.MINIMIZE:\n",
    "                # minimize\n",
    "                p = getProjection(-pred_cost[i], tight_ctrs[i])\n",
    "            if optmodel.modelSense == EPO.MAXIMIZE:\n",
    "                # maximize\n",
    "                p = getProjection(pred_cost[i], tight_ctrs[i])\n",
    "            # calculate cosine similarity\n",
    "            loss[i] = - F.cosine_similarity(F.normalize(pred_cost[i].unsqueeze(0)), \n",
    "                                            F.normalize(p.unsqueeze(0)))\n",
    "            print(\"Predicted Cost:\")\n",
    "            print(pred_cost[i].detach().numpy())\n",
    "            print(\"Projection:\")\n",
    "            print(p.detach().numpy())\n",
    "            print(\"Loss:\")\n",
    "            print(loss[i].item())\n",
    "            break\n",
    "        return loss\n",
    "\n",
    "        \n",
    "def getProjection(cp, ctr):\n",
    "    \"\"\"\n",
    "    A function to get the projection of the vector onto the polar cone via solving a quadratic programming\n",
    "    \"\"\"\n",
    "    # ceate a model\n",
    "    m = gp.Model(\"shortest path\")\n",
    "    # turn off output\n",
    "    m.Params.outputFlag = 0\n",
    "    # varibles\n",
    "    p = m.addVars(len(cp), name=\"x\", lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    λ = m.addVars(len(ctr), name=\"lambda\")\n",
    "    # onjective function\n",
    "    obj = gp.quicksum((cp[i].item() - p[i]) ** 2 for i in range(len(cp)))\n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "    # constraints\n",
    "    print(\"Binding Constraints:\")\n",
    "    for constr in ctr:\n",
    "        print(constr)\n",
    "    for i in range(len(cp)):\n",
    "        m.addConstr(gp.quicksum(ctr[j,i] * λ[j] for j in range(len(ctr))) == p[i])\n",
    "    # focus on numeric problem\n",
    "    m.Params.NumericFocus = 3\n",
    "    # solve\n",
    "    m.update()\n",
    "    m.optimize()\n",
    "    # get solutions\n",
    "    λ_val = np.array([λ[i].x for i in λ])\n",
    "    # normalize\n",
    "    λ_norm = λ_val / np.linalg.norm(λ_val)\n",
    "    # get normalized projection\n",
    "    proj = torch.FloatTensor(λ_norm@ctr)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67660513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init loss\n",
    "pca_loss = polarConeAngle(optmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fb9a6",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c332205",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding Constraints:\n",
      "[-1.  0.]\n",
      "[0. 1.]\n",
      "Predicted Cost:\n",
      "[1.0932196  0.43150395]\n",
      "Projection:\n",
      "[0. 1.]\n",
      "Loss:\n",
      "-0.367144376039505\n",
      "Cost:\n",
      "[0.14596194 0.5064134 ]\n",
      "Solution:\n",
      "True: [0. 1.] Prediction: [1.0, 0.0]\n",
      "True: 0.51, Prediction: 0.15\n"
     ]
    }
   ],
   "source": [
    "for data in loader_train:\n",
    "    x, c, w, z, t_ctr = data\n",
    "    # forward pass\n",
    "    cp = reg(x)\n",
    "    loss = pca_loss(cp, t_ctr)\n",
    "    # check sol\n",
    "    for i in range(len(cp)):\n",
    "        print(\"Cost:\")\n",
    "        print(c[i].detach().numpy())\n",
    "        optmodel.setObj(cp[i])\n",
    "        wpi, zpi = optmodel.solve()\n",
    "        print(\"Solution:\")\n",
    "        print(\"True:\", w[i].detach().numpy(), \"Prediction:\", wpi)\n",
    "        print(\"True: {:.2f}, Prediction: {:.2f}\".format(z[i].item(), c[i].detach().numpy()@wpi))\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d8eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
